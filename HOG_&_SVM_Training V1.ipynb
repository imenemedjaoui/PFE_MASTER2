{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 1 : Reading Dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading vehicles images...\n",
      " Done !\n",
      "(9456, 32, 32)\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(' Reading vehicles images...')\n",
    "\n",
    "vehicle =  glob.glob('./vehicles/*/*.png')\n",
    "gti_right =  glob.glob('./GTI_Right/*.png')\n",
    "vehicle_images = np.concatenate([vehicle, gti_right])\n",
    "\n",
    "vehicle_images_original = []\n",
    "for imagePath in vehicle_images:\n",
    "    readImg = cv2.imread(imagePath)\n",
    "    Img = cv2.cvtColor(readImg, cv2.COLOR_BGR2GRAY)\n",
    "    Img = cv2.resize(Img,(32, 32))\n",
    "    vehicle_images_original.append(Img)\n",
    "    \n",
    "print(' Done !')\n",
    "#imgPlot = plt.imshow(vehicle_images_original[3400])\n",
    "#print(vehicle_images_original[3400].shape)\n",
    "vehicles_img = np.asarray(vehicle_images_original)\n",
    "print(vehicles_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading non-vehicles images...\n",
      " Done\n",
      "\n",
      "(5068, 32, 32)\n",
      "N째 of vehicle images loaded : 9456\n",
      "N째 of non-vehicle images loaded : 5068\n",
      "Wall time: 45.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(' Reading non-vehicles images...')\n",
    "\n",
    "non_vehicle_images = glob.glob('./non-vehicles/Extras/*.png')\n",
    "\n",
    "non_vehicle_images_original = []\n",
    "for imagePath in non_vehicle_images:\n",
    "    readImg = cv2.imread(imagePath)\n",
    "    Img = cv2.cvtColor(readImg, cv2.COLOR_BGR2GRAY)\n",
    "    Img = cv2.resize(Img,(32, 32))\n",
    "    non_vehicle_images_original.append(Img)\n",
    "    \n",
    "print(' Done\\n')\n",
    "\n",
    "non_vehicles_img = np.asarray(non_vehicle_images_original)\n",
    "print(non_vehicles_img.shape)\n",
    "\n",
    "print(\"N째 of vehicle images loaded : \" + str(len(vehicle_images_original)))\n",
    "print(\"N째 of non-vehicle images loaded : \" + str(len(non_vehicle_images_original)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 : Extract Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 : HOG Features Extracting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        hog_features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, visualize=vis, feature_vector=feature_vec)\n",
    "        return hog_features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        hog_features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                      transform_sqrt=True, visualize=vis, feature_vector=feature_vec)\n",
    "        return hog_features\n",
    "\n",
    "# Return extracted features \n",
    "def ExtractFeatures(images, orient, pix_per_cell, cell_per_block):\n",
    "    featureList = []\n",
    "    for Img in images:\n",
    "        local_features = get_hog_features(Img, orient, pix_per_cell, cell_per_block, False, True)\n",
    "        featureList.append(local_features)\n",
    "    return featureList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 Extracting Features from Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "orient = 16\n",
    "pixels = 8\n",
    "cells = 2\n",
    "# Extract features for vehicle images \n",
    "vehicleFeatures= ExtractFeatures(vehicle_images_original, orient, pixels, cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract features for non-vehicle images\n",
    "nonVehicleFeatures = ExtractFeatures(non_vehicle_images_original, orient, pixels, cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features list is  (14524, 576)\n",
      "Shape of the label list is  (14524,)\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "featuresList= np.vstack([vehicleFeatures, nonVehicleFeatures])\n",
    "print(\"Shape of features list is \", featuresList.shape)\n",
    "labelList= np.concatenate([np.ones(len(vehicleFeatures)), np.zeros(len(nonVehicleFeatures))])\n",
    "print(\"Shape of the label list is \", labelList.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8714, 576)\n",
      "(2905, 576)\n",
      "(2905, 576)\n",
      "Wall time: 723 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Data Preprocessing \"\"\"\n",
    "# train test split of data\n",
    "X_train,  X_test1,Y_train, Y_test1 = train_test_split(featuresList, labelList, test_size=0.4)\n",
    "\n",
    "X_valid, X_test, Y_valid, Y_test = train_test_split(X_test1, Y_test1, test_size=0.5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8714, 576)\n",
      "(2905, 576)\n",
      "(2905, 576)\n",
      "Wall time: 394 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#normalization and scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled= scaler.transform(X_train)\n",
    "X_test_scaled= scaler.transform(X_test)\n",
    "X_valid_scaled= scaler.transform(X_valid)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(X_valid_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Accuracy is   0.9613266008721597\n",
      "validation Accuracy is   0.9490533562822719\n",
      "Confusion matrix :\n",
      " [[ 914   98]\n",
      " [  68 1825]]\n",
      "\n",
      "Classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92      1012\n",
      "         1.0       0.95      0.96      0.96      1893\n",
      "\n",
      "    accuracy                           0.94      2905\n",
      "   macro avg       0.94      0.93      0.94      2905\n",
      "weighted avg       0.94      0.94      0.94      2905\n",
      "\n",
      "Wall time: 994 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Define and Train a classifier \"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classifier1= LinearSVC(dual = False)\n",
    "classifier1.fit(X_train,Y_train)\n",
    "print(\"training Accuracy is  \", classifier1.score(X_train,Y_train) )\n",
    "#print(\"test Accuracy is  \", classifier1.score(X_test,Y_test) )\n",
    "print(\"validation Accuracy is  \", classifier1.score(X_valid,Y_valid) )\n",
    "Y_pred = classifier1.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(\"Confusion matrix :\\n\",cm)\n",
    "\n",
    "cr = classification_report(Y_test, Y_pred)\n",
    "print(\"\\nClassification report :\\n\",cr)\n",
    "\n",
    "#cv_score = cross_val_score(classifier1,X_valid,Y_valid,cv = 10)\n",
    "#print(\"validation Accuracy is \", cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 368 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'classifier2_Linearsvm_16_8_2.xml'\n",
    "pickle.dump(classifier1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of validation is : [0.93248945 0.93389592 0.91549296 0.91267606 0.92112676]\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the model from disk\n",
    "\n",
    "classifier1 = pickle.load(open(filename, 'rb'))\n",
    "scores = cross_val_score(classifier1,X_valid,Y_valid,cv=5 )\n",
    "print(\"accuracy of validation is :\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
