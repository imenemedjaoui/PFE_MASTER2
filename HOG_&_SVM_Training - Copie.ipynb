{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading vehicles images...\n",
      " Done\n",
      "(5738, 32, 32)\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#time function always at the beginning of the code block\n",
    "\"\"\" step 1 : reading the images \"\"\"\n",
    "print(' Reading vehicles images...')\n",
    "vehicle_images = []\n",
    "\n",
    "GTI_far = glob.glob('./data/data1/vehicles/GTI_Far/*.png')\n",
    "GTI_left = glob.glob('./data/data1/vehicles/GTI_Left/*.png')\n",
    "GTI_middleClose = glob.glob('./data/data1/vehicles/MiddleClose/*.png')\n",
    "GTI_right = glob.glob('./data/data1/vehicles/GTI_Right/*.png')\n",
    "GTI_extracted = glob.glob('./data/data1/vehicles/KITTI_exctracted//*.png')\n",
    "cars_img = glob.glob('./data/car_data/train/A*/*.jpg')\n",
    "cars_img2 = glob.glob('./data/car_data/train/B*/*.jpg')\n",
    "cars_img3 = glob.glob('./data/car_data/train/C*/*.jpg')\n",
    "\n",
    "vehicle_images = np.concatenate([GTI_far, GTI_left, GTI_middleClose, GTI_right, GTI_extracted, cars_img, cars_img2, cars_img3])\n",
    "\n",
    "vehicle_images_original = []\n",
    "for imagePath in vehicle_images:\n",
    "    readImg = cv2.imread(imagePath)\n",
    "    Img = cv2.cvtColor(readImg, cv2.COLOR_BGR2GRAY)\n",
    "    Img = cv2.resize(Img,(32, 32))\n",
    "    vehicle_images_original.append(Img)\n",
    "    \n",
    "print(' Done')\n",
    "\n",
    "vehicles_img = np.asarray(vehicle_images_original)\n",
    "print(vehicles_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Reading non-vehicles images...\n",
      " Done\n",
      "(4115, 32, 32)\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(' Reading non-vehicles images...')\n",
    "non_vehicles_images = []\n",
    "Extras = glob.glob('./data/non-vehicles/*.jpg')\n",
    "#extras2 = glob.glob('./data/data1/non-vehicles/Extras//*.png')\n",
    "GTI = glob.glob('./data/data1/non-vehicles/GTI/*.png')\n",
    "\n",
    "non_vehicle_images = np.concatenate([Extras, GTI])\n",
    "\n",
    "non_vehicle_images_original = []\n",
    "for imagePath in non_vehicle_images:\n",
    "    readImg = cv2.imread(imagePath)\n",
    "    Img = cv2.cvtColor(readImg, cv2.COLOR_BGR2GRAY)\n",
    "    Img = cv2.resize(Img,(32, 32))\n",
    "    non_vehicle_images_original.append(Img)\n",
    "    \n",
    "print(' Done')\n",
    "\n",
    "non_vehicles_img = np.asarray(non_vehicle_images_original)\n",
    "print(non_vehicles_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N° of vehicle images loaded : 5738\n",
      "N° of non-vehicle images loaded : 4115\n",
      "Wall time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"N° of vehicle images loaded : \" + str(len(vehicle_images_original)))\n",
    "print(\"N° of non-vehicle images loaded : \" + str(len(non_vehicle_images_original)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" HOG functions \"\"\"\n",
    "# Return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        hog_features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  visualize=vis, feature_vector=feature_vec)\n",
    "        return hog_features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        hog_features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       visualize=vis, feature_vector=feature_vec)\n",
    "        return hog_features\n",
    "\n",
    "# Return extracted features \n",
    "def ExtractFeatures(images, orient, pix_per_cell, cell_per_block):\n",
    "    featureList = []\n",
    "    for Img in images:\n",
    "        local_features = get_hog_features(Img, orient, pix_per_cell, cell_per_block, False, True)\n",
    "        featureList.append(local_features)\n",
    "    return featureList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# can be used to visualize confusion matrix if needed\n",
    "# Extract features for vehicle images \n",
    "vehicleFeatures= ExtractFeatures(vehicle_images_original, 10, 8, 4)\n",
    "\n",
    "#vehicleFeat = np.asarray(vehicleFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract features for non-vehicle images\n",
    "nonVehicleFeatures = ExtractFeatures(non_vehicle_images_original, 10, 8, 4)\n",
    "\n",
    "#nonVehicleFeat = np.asarray(nonVehicleFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features list is  (9853, 160)\n",
      "Shape of the label list is  (9853,)\n",
      "Wall time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "featuresList= np.vstack([vehicleFeatures, nonVehicleFeatures])\n",
    "print(\"Shape of features list is \", featuresList.shape)\n",
    "labelList= np.concatenate([np.ones(len(vehicleFeatures)), np.zeros(len(nonVehicleFeatures))])\n",
    "print(\"Shape of the label list is \", labelList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7882, 160)\n",
      "(1971, 160)\n",
      "Wall time: 192 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Data Preprocessing \"\"\"\n",
    "# train test split of data\n",
    "X_train,  X_test,Y_train, Y_test = train_test_split(featuresList, labelList, test_size=0.2, shuffle=True)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7882, 160)\n",
      "(1971, 160)\n",
      "Wall time: 293 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#normalization and scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled= scaler.transform(X_train)\n",
    "X_test_scaled= scaler.transform(X_test)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy is   0.9528158295281582\n",
      "training Accuracy is   0.9663790916011165\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\" Define and Train a classifier \"\"\"\n",
    "from sklearn.svm import LinearSVC\n",
    "classifier1= LinearSVC()\n",
    "classifier1.fit(X_train,Y_train)\n",
    "print(\"test Accuracy is  \", classifier1.score(X_test,Y_test) )\n",
    "print(\"training Accuracy is  \", classifier1.score(X_train,Y_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filename = 'classifier14.xml'\n",
    "pickle.dump(classifier1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
